use tauri::{State, Emitter};
use tokio::sync::Mutex;
use serde::{Deserialize, Serialize};

use crate::core::ai_manager::AIManager;
use crate::core::ai_provider::{AIRequest, AIModel, ConnectionTestResult, ChatMessage};
use crate::core::ai_config::AIConfig;
use crate::core::prompt_manager::{PromptTemplate, CommitContext};
use crate::core::conversation_logger::ConversationRecord;

/**
 * AIç›¸å…³çš„Tauriå‘½ä»¤
 * ä½œè€…ï¼šEvilek
 * ç¼–å†™æ—¥æœŸï¼š2025-07-25
 */

#[derive(Debug, Serialize, Deserialize)]
pub struct GenerateCommitRequest {
    pub selected_files: Vec<String>,
    pub additional_context: Option<String>,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct GenerateCommitResponse {
    pub message: String,
    pub confidence: f32,
    pub processing_time_ms: u64,
    pub model_used: String,
    /// æ¨ç†å†…å®¹ï¼ˆ<think>æ ‡ç­¾å†…çš„å†…å®¹ï¼‰
    /// ä½œè€…ï¼šEvilek
    /// ç¼–å†™æ—¥æœŸï¼š2025-01-10
    pub reasoning_content: Option<String>,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct TestConnectionRequest {
    pub provider_id: String,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct GetModelsRequest {
    pub provider_id: String,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct ProvidersInfoResponse {
    pub providers: Vec<ProviderInfo>,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct ProviderInfo {
    pub id: String,
    pub name: String,
    pub available: bool,
}

/// è·å–AIé…ç½®
#[tauri::command]
pub async fn get_ai_config(
    ai_manager: State<'_, Mutex<AIManager>>,
) -> Result<AIConfig, String> {
    let manager = ai_manager.lock().await;
    Ok(manager.get_config().await)
}

/// æ›´æ–°AIé…ç½®
#[tauri::command]
pub async fn update_ai_config(
    ai_manager: State<'_, Mutex<AIManager>>,
    config: AIConfig,
) -> Result<(), String> {
    let manager = ai_manager.lock().await;
    manager.update_config(config).await
        .map_err(|e| format!("Failed to update AI config: {}", e))
}

/// è·å–æ‰€æœ‰æä¾›å•†ä¿¡æ¯
#[tauri::command]
pub async fn get_providers_info(
    ai_manager: State<'_, Mutex<AIManager>>,
) -> Result<ProvidersInfoResponse, String> {
    let manager = ai_manager.lock().await;
    let providers_info = manager.get_providers_info().await;
    
    let mut providers = Vec::new();
    for (id, name) in providers_info {
        let available = manager.is_provider_available(&id).await;
        providers.push(ProviderInfo {
            id,
            name,
            available,
        });
    }
    
    Ok(ProvidersInfoResponse { providers })
}

/// è·å–æŒ‡å®šæä¾›å•†çš„æ¨¡å‹åˆ—è¡¨
#[tauri::command]
pub async fn get_models_for_provider(
    request: GetModelsRequest,
    ai_manager: State<'_, Mutex<AIManager>>,
) -> Result<Vec<AIModel>, String> {
    let manager = ai_manager.lock().await;
    manager.get_models_for_provider(&request.provider_id).await
        .map_err(|e| format!("Failed to get models: {}", e))
}

/// ä½¿ç”¨ä¸´æ—¶é…ç½®è·å–æŒ‡å®šæä¾›å•†çš„æ¨¡å‹åˆ—è¡¨
#[tauri::command(rename_all = "camelCase")]
pub async fn get_models_with_temp_config(
    provider_id: String,
    temp_config: AIConfig,
) -> Result<Vec<AIModel>, String> {
    use crate::core::providers;

    // ä½¿ç”¨ä¸´æ—¶é…ç½®åˆ›å»ºæä¾›å•†å·¥å‚
    let factory = providers::create_provider_factory(&temp_config);

    // è·å–æ¨¡å‹åˆ—è¡¨
    factory.get_models(&provider_id).await
        .map_err(|e| format!("Failed to get models: {}", e))
}

/// æµ‹è¯•æä¾›å•†è¿æ¥
#[tauri::command]
pub async fn test_provider_connection(
    request: TestConnectionRequest,
    ai_manager: State<'_, Mutex<AIManager>>,
) -> Result<ConnectionTestResult, String> {
    let manager = ai_manager.lock().await;
    manager.test_provider_connection(&request.provider_id).await
        .map_err(|e| format!("Failed to test connection: {}", e))
}

/// ä½¿ç”¨ä¸´æ—¶é…ç½®æµ‹è¯•æä¾›å•†è¿æ¥
#[tauri::command(rename_all = "camelCase")]
pub async fn test_connection_with_temp_config(
    provider_id: String,
    temp_config: AIConfig,
) -> Result<ConnectionTestResult, String> {
    use crate::core::providers;

    // ä½¿ç”¨ä¸´æ—¶é…ç½®åˆ›å»ºæä¾›å•†å·¥å‚
    let factory = providers::create_provider_factory(&temp_config);

    // æµ‹è¯•è¿æ¥
    factory.test_connection(&provider_id).await
        .map_err(|e| format!("Failed to test connection: {}", e))
}

/// åˆ·æ–°æä¾›å•†æ¨¡å‹åˆ—è¡¨
#[tauri::command]
pub async fn refresh_provider_models(
    request: GetModelsRequest,
    ai_manager: State<'_, Mutex<AIManager>>,
) -> Result<Vec<AIModel>, String> {
    let manager = ai_manager.lock().await;
    manager.refresh_provider_models(&request.provider_id).await
        .map_err(|e| format!("Failed to refresh models: {}", e))
}

/// ä½¿ç”¨AIç”Ÿæˆæäº¤æ¶ˆæ¯ï¼ˆå¢å¼ºç‰ˆï¼‰
#[tauri::command]
pub async fn generate_commit_message_ai(
    request: GenerateCommitRequest,
    ai_manager: State<'_, Mutex<AIManager>>,
    git_engine: State<'_, Mutex<crate::core::git_engine::GitEngine>>,
) -> Result<GenerateCommitResponse, String> {
    use std::time::Instant;
    
    let start_time = Instant::now();
    
    // è·å–GitçŠ¶æ€å’Œå·®å¼‚ä¿¡æ¯
    let git_status = {
        let engine = git_engine.lock().await;
        engine.get_status()
            .map_err(|e| format!("Failed to get git status: {}", e))?
    };
    
    let diff_summary = {
        let engine = git_engine.lock().await;
        engine.get_diff_summary(&request.selected_files)
            .map_err(|e| format!("Failed to get diff summary: {}", e))?
    };
    
    // è·å–AIé…ç½®
    let manager = ai_manager.lock().await;
    let config = manager.get_config().await;
    
    // æ„å»ºæç¤ºè¯ï¼ˆå‚è€ƒDish AI Commitçš„æç¤ºè¯æ¨¡æ¿ï¼‰
    let system_prompt = create_commit_system_prompt(&config);
    let user_prompt = format!(
        "è¯·ä¸ºä»¥ä¸‹Gitæ›´æ”¹ç”Ÿæˆæäº¤æ¶ˆæ¯ï¼š\n\nåˆ†æ”¯: {}\næ–‡ä»¶æ•°é‡: {}\nä¿®æ”¹çš„æ–‡ä»¶:\n{}\n\nå·®å¼‚æ‘˜è¦:\n{}\n\n{}",
        git_status.branch,
        request.selected_files.len(),
        request.selected_files.join("\n- "),
        diff_summary,
        request.additional_context.unwrap_or_default()
    );
    
    // æ„å»ºAIè¯·æ±‚
    let ai_request = AIRequest {
        messages: vec![
            ChatMessage {
                role: "system".to_string(),
                content: system_prompt,
            },
            ChatMessage {
                role: "user".to_string(),
                content: user_prompt,
            },
        ],
        model: config.base.model.clone(),
        temperature: Some(config.advanced.temperature),
        max_tokens: Some(config.advanced.max_tokens),
        stream: Some(false),
    };
    
    // è°ƒç”¨AIç”Ÿæˆ
    let response = manager.generate_commit_message(ai_request).await
        .map_err(|e| format!("Failed to generate commit message: {}", e))?;
    
    let processing_time = start_time.elapsed().as_millis() as u64;
    
    Ok(GenerateCommitResponse {
        message: response.content,
        confidence: 0.85, // ç®€åŒ–çš„ç½®ä¿¡åº¦
        processing_time_ms: processing_time,
        model_used: response.model,
        reasoning_content: response.reasoning_content, // æ·»åŠ æ¨ç†å†…å®¹ - Author: Evilek, Date: 2025-01-10
    })
}

/// åˆ›å»ºæäº¤æ¶ˆæ¯ç³»ç»Ÿæç¤ºè¯ï¼ˆä¼˜åŒ–ç‰ˆï¼Œé¿å…æ ‡é¢˜æ ¼å¼å¹²æ‰°ï¼‰
/// ä½œè€…ï¼šEvilek
/// ç¼–å†™æ—¥æœŸï¼š2025-01-29
fn create_commit_system_prompt(config: &AIConfig) -> String {
    let language = &config.base.language;
    let enable_emoji = config.features.enable_emoji;
    let enable_body = config.features.enable_body;

    format!(
        r#"ä½ æ˜¯ä¸“ä¸šçš„Gitæäº¤æ¶ˆæ¯ç”ŸæˆåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»£ç å˜æ›´ç”Ÿæˆç®€æ´ã€å‡†ç¡®çš„æäº¤æ¶ˆæ¯ã€‚

æ ¸å¿ƒè¦æ±‚ï¼š
- æ ¹æ®å®é™…æ›´æ”¹ç¡®å®šæ­¤æ¬¡æäº¤çš„çœŸå®æ„å›¾
- è¯†åˆ«å·²ä¿®æ”¹çš„æ¨¡å—/æ–‡ä»¶å’Œä¿®æ”¹ç±»å‹
- ä½¿ç”¨{}ç¼–å†™æ‰€æœ‰å†…å®¹ï¼ˆæŠ€æœ¯æœ¯è¯­å’ŒèŒƒå›´é™¤å¤–ï¼‰
- èŒƒå›´å’ŒæŠ€æœ¯æœ¯è¯­ä»…ä½¿ç”¨è‹±æ–‡
- ä¸¥æ ¼éµå¾ªæ ¼å¼ï¼š<type>(<scope>): <description>
- {}åŒ…å«é€‚å½“çš„è¡¨æƒ…ç¬¦å·
- {}åŒ…å«è¯¦ç»†çš„æäº¤æè¿°

æäº¤ç±»å‹è¯´æ˜ï¼š
feat: æ–°åŠŸèƒ½, fix: é”™è¯¯ä¿®å¤, docs: æ–‡æ¡£æ›´æ”¹, style: ä»£ç æ ¼å¼, refactor: é‡æ„, test: å¢åŠ æµ‹è¯•, chore: æ„å»ºè¿‡ç¨‹æˆ–è¾…åŠ©å·¥å…·çš„å˜åŠ¨

ä¸¥æ ¼ç¦æ­¢ï¼š
- ä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€é—®å€™æˆ–é¢å¤–æ–‡æœ¬
- ä¸è¦æ·»åŠ æ ¼å¼è¯´æ˜æˆ–å…ƒæ•°æ®
- ä¸è¦åœ¨è¾“å‡ºä¸­åŒ…å«ä¸‰é‡åå¼•å·æˆ–æ ‡é¢˜æ ¼å¼
- ä¸è¦æ·»åŠ ä»»ä½•è¯„è®ºæˆ–é—®é¢˜
- ä¸è¦åç¦»æ‰€éœ€æ ¼å¼

ç›´æ¥è¾“å‡ºæäº¤æ¶ˆæ¯ï¼Œæ— éœ€å…¶ä»–å†…å®¹ã€‚"#,
        language,
        if enable_emoji { "å¯ç”¨æ—¶" } else { "ç¦ç”¨æ—¶" },
        if enable_body { "å¯ç”¨æ—¶" } else { "ç¦ç”¨æ—¶" }
    )
}

/// ä½¿ç”¨æç¤ºæ¨¡æ¿ç”Ÿæˆæäº¤æ¶ˆæ¯
/// ä½œè€…ï¼šEvilek
/// ç¼–å†™æ—¥æœŸï¼š2025-07-28
/// æ›´æ–°æ—¥æœŸï¼š2025-08-04
#[tauri::command]
pub async fn generate_commit_with_template(
    ai_manager: State<'_, Mutex<AIManager>>,
    git_engine: State<'_, Mutex<crate::core::git_engine::GitEngine>>,
    template_id: String,
    diff: String,
    staged_files: Vec<String>,
    branch_name: Option<String>,
) -> Result<String, String> {
    let manager = ai_manager.lock().await;

    // è·å–å½“å‰ä»“åº“è·¯å¾„
    let repository_path = {
        let engine = git_engine.lock().await;
        engine.get_repository_path()
    };

    // ä»AIé…ç½®ä¸­è·å–è¯­è¨€è®¾ç½®
    let config = manager.get_config().await;
    let language = match config.base.language.as_str() {
        "Simplified Chinese" => "zh-CN",
        "Traditional Chinese" => "zh-TW",
        "English" => "en",
        "Japanese" => "ja",
        "Korean" => "ko",
        "French" => "fr",
        "German" => "de",
        "Spanish" => "es",
        "Russian" => "ru",
        "Portuguese" => "pt",
        "Italian" => "it",
        "Dutch" => "nl",
        "Swedish" => "sv",
        "Czech" => "cs",
        "Polish" => "pl",
        "Turkish" => "tr",
        "Vietnamese" => "vi",
        "Thai" => "th",
        "Indonesian" => "id",
        _ => "en", // é»˜è®¤è‹±æ–‡
    };

    let context = CommitContext {
        diff,
        staged_files,
        branch_name,
        commit_type: None,
        max_length: None,
        language: language.to_string(), // ä½¿ç”¨é…ç½®ä¸­çš„è¯­è¨€è®¾ç½®
    };

    match manager.generate_commit_with_template(&template_id, context, repository_path).await {
        Ok(response) => {
            Ok(response.content)
        },
        Err(e) => {
            Err(format!("Failed to generate commit message: {}", e))
        },
    }
}

/// è·å–æ‰€æœ‰å¯ç”¨çš„æç¤ºæ¨¡æ¿
#[tauri::command]
pub async fn get_prompt_templates(
    ai_manager: State<'_, Mutex<AIManager>>,
) -> Result<Vec<PromptTemplate>, String> {
    let manager = ai_manager.lock().await;
    Ok(manager.get_prompt_templates().await)
}

/// æ£€æŸ¥æ¨¡æ¿æ˜¯å¦æ”¯æŒä¸¤æ®µå¼å¤„ç†
/// ä½œè€…ï¼šEvilek
/// ç¼–å†™æ—¥æœŸï¼š2025-08-08
#[tauri::command]
pub async fn check_template_two_phase_support(
    ai_manager: State<'_, Mutex<AIManager>>,
    template_id: String,
) -> Result<bool, String> {
    let manager = ai_manager.lock().await;
    let prompt_manager = manager.get_prompt_manager().await;
    Ok(prompt_manager.supports_two_phase(&template_id))
}

/// è·å–æ¨¡æ¿çš„ä¸¤æ®µå¼é…ç½®çŠ¶æ€
/// ä½œè€…ï¼šEvilek
/// ç¼–å†™æ—¥æœŸï¼š2025-08-08
#[tauri::command]
pub async fn get_template_two_phase_status(
    ai_manager: State<'_, Mutex<AIManager>>,
    template_id: String,
) -> Result<Option<(bool, bool)>, String> {
    let manager = ai_manager.lock().await;
    let prompt_manager = manager.get_prompt_manager().await;
    Ok(prompt_manager.get_two_phase_status(&template_id))
}

/// åˆ›å»ºè‡ªå®šä¹‰æ¨¡æ¿
/// ä½œè€…ï¼šEvilek
/// ç¼–å†™æ—¥æœŸï¼š2025-01-29
#[tauri::command]
pub async fn create_custom_template(
    ai_manager: State<'_, Mutex<AIManager>>,
    template: PromptTemplate,
) -> Result<(), String> {
    let manager = ai_manager.lock().await;
    manager.create_custom_template(template).await
        .map_err(|e| format!("Failed to create template: {}", e))
}

/// æ›´æ–°æ¨¡æ¿
/// ä½œè€…ï¼šEvilek
/// ç¼–å†™æ—¥æœŸï¼š2025-01-29
#[tauri::command]
pub async fn update_template(
    ai_manager: State<'_, Mutex<AIManager>>,
    template: PromptTemplate,
) -> Result<(), String> {
    let manager = ai_manager.lock().await;
    manager.update_template(template).await
        .map_err(|e| format!("Failed to update template: {}", e))
}

/// åˆ é™¤æ¨¡æ¿
/// ä½œè€…ï¼šEvilek
/// ç¼–å†™æ—¥æœŸï¼š2025-01-29
#[tauri::command]
pub async fn delete_template(
    ai_manager: State<'_, Mutex<AIManager>>,
    template_id: String,
) -> Result<(), String> {
    let manager = ai_manager.lock().await;
    manager.delete_template(&template_id).await
        .map_err(|e| format!("Failed to delete template: {}", e))
}

/// è·å–è‡ªå®šä¹‰æ¨¡æ¿åˆ—è¡¨
/// ä½œè€…ï¼šEvilek
/// ç¼–å†™æ—¥æœŸï¼š2025-01-29
#[tauri::command]
pub async fn get_custom_templates(
    ai_manager: State<'_, Mutex<AIManager>>,
) -> Result<Vec<PromptTemplate>, String> {
    let manager = ai_manager.lock().await;
    Ok(manager.get_custom_templates().await)
}

/// è·å–é»˜è®¤æ¨¡æ¿åˆ—è¡¨
/// ä½œè€…ï¼šEvilek
/// ç¼–å†™æ—¥æœŸï¼š2025-01-29
#[tauri::command]
pub async fn get_default_templates(
    ai_manager: State<'_, Mutex<AIManager>>,
) -> Result<Vec<PromptTemplate>, String> {
    let manager = ai_manager.lock().await;
    Ok(manager.get_default_templates().await)
}

/// æ·»åŠ è‡ªå®šä¹‰æç¤ºæ¨¡æ¿
#[tauri::command]
pub async fn add_prompt_template(
    ai_manager: State<'_, Mutex<AIManager>>,
    template: PromptTemplate,
) -> Result<(), String> {
    let manager = ai_manager.lock().await;
    manager.add_prompt_template(template).await;
    Ok(())
}

/// è·å–å¯¹è¯è®°å½•
/// ä½œè€…ï¼šEvilek
/// ç¼–å†™æ—¥æœŸï¼š2025-01-30
#[tauri::command]
pub async fn get_conversation_history(
    ai_manager: State<'_, Mutex<AIManager>>,
) -> Result<Vec<ConversationRecord>, String> {
    let manager = ai_manager.lock().await;
    Ok(manager.get_conversation_history().await)
}

/// æ¸…ç©ºå¯¹è¯è®°å½•
/// ä½œè€…ï¼šEvilek
/// ç¼–å†™æ—¥æœŸï¼š2025-01-30
#[tauri::command]
pub async fn clear_conversation_history(
    ai_manager: State<'_, Mutex<AIManager>>,
) -> Result<(), String> {
    let manager = ai_manager.lock().await;
    manager.clear_conversation_history().await
        .map_err(|e| format!("Failed to clear conversation history: {}", e))
}

/// æ ¹æ®ä»“åº“è·¯å¾„è·å–å¯¹è¯è®°å½•
/// ä½œè€…ï¼šEvilek
/// ç¼–å†™æ—¥æœŸï¼š2025-08-04
#[tauri::command]
pub async fn get_conversation_history_by_repository(
    ai_manager: State<'_, Mutex<AIManager>>,
    repository_path: Option<String>,
) -> Result<Vec<ConversationRecord>, String> {
    let manager = ai_manager.lock().await;
    manager.get_conversation_history_by_repository(repository_path.as_deref()).await
        .map_err(|e| format!("Failed to get conversation history: {}", e))
}

/// è·å–æ‰€æœ‰ä»“åº“è·¯å¾„åˆ—è¡¨
/// ä½œè€…ï¼šEvilek
/// ç¼–å†™æ—¥æœŸï¼š2025-08-04
#[tauri::command]
pub async fn get_repository_paths(
    ai_manager: State<'_, Mutex<AIManager>>,
) -> Result<Vec<String>, String> {
    let manager = ai_manager.lock().await;
    manager.get_repository_paths().await
        .map_err(|e| format!("Failed to get repository paths: {}", e))
}

/// æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨åˆ†å±‚æäº¤
/// ä½œè€…ï¼šEvilek
/// ç¼–å†™æ—¥æœŸï¼š2025-08-04
/// æ›´æ–°æ—¥æœŸï¼š2025-08-05
#[tauri::command]
pub async fn should_use_layered_commit(
    ai_manager: State<'_, Mutex<AIManager>>,
    git_engine: State<'_, Mutex<crate::core::git_engine::GitEngine>>,
    template_id: String,
    diff: String,
    staged_files: Vec<String>,
) -> Result<bool, String> {
    use crate::core::layered_commit_manager::LayeredCommitManager;
    use std::sync::Arc;
    use tokio::sync::RwLock;

    // åˆ›å»ºLayeredCommitManagerå®ä¾‹
    let ai_manager_arc = Arc::new(RwLock::new(ai_manager.lock().await.clone()));
    let git_engine_arc = Arc::new(RwLock::new(git_engine.lock().await.clone()));
    let manager = LayeredCommitManager::new(ai_manager_arc, git_engine_arc);

    // è°ƒç”¨çœŸæ­£çš„åˆ†å±‚æäº¤æ£€æµ‹é€»è¾‘
    manager.should_use_layered_commit(&template_id, &diff, &staged_files)
        .await
        .map_err(|e| format!("æ£€æŸ¥åˆ†å±‚æäº¤å¤±è´¥: {}", e))
}

/// å…¨å±€åˆ†å±‚æäº¤ç®¡ç†å™¨å®ä¾‹ï¼Œç”¨äºä»»åŠ¡å–æ¶ˆ
/// Author: Evilek, Date: 2025-01-09
use std::sync::Mutex as StdMutex;
use std::sync::Arc as StdArc;
use once_cell::sync::Lazy;

static LAYERED_COMMIT_MANAGER: Lazy<StdMutex<Option<StdArc<crate::core::layered_commit_manager::LayeredCommitManager>>>> =
    Lazy::new(|| StdMutex::new(None));

/// æ‰§è¡Œåˆ†å±‚æäº¤
/// ä½œè€…ï¼šEvilek
/// ç¼–å†™æ—¥æœŸï¼š2025-08-04
/// æ›´æ–°æ—¥æœŸï¼š2025-08-05
#[tauri::command]
pub async fn execute_layered_commit(
    ai_manager: State<'_, Mutex<AIManager>>,
    git_engine: State<'_, Mutex<crate::core::git_engine::GitEngine>>,
    app_handle: tauri::AppHandle,
    templateId: String,
    stagedFiles: Vec<String>,
    branchName: Option<String>,
) -> Result<crate::core::layered_commit_manager::LayeredCommitResult, String> {
    use crate::core::layered_commit_manager::LayeredCommitManager;
    use std::sync::Arc;
    use tokio::sync::RwLock;



    // è·å–å½“å‰ä»“åº“è·¯å¾„
    let repository_path = {
        let engine = git_engine.lock().await;
        engine.get_repository_path()
    };

    // åˆ›å»ºLayeredCommitManagerå®ä¾‹
    let ai_manager_arc = Arc::new(RwLock::new(ai_manager.lock().await.clone()));
    let git_engine_arc = Arc::new(RwLock::new(git_engine.lock().await.clone()));
    let manager = StdArc::new(LayeredCommitManager::new(ai_manager_arc, git_engine_arc));

    // ä¿å­˜ç®¡ç†å™¨å®ä¾‹åˆ°å…¨å±€å˜é‡ï¼Œç”¨äºä»»åŠ¡å–æ¶ˆ - Author: Evilek, Date: 2025-01-09
    {
        let mut global_manager = LAYERED_COMMIT_MANAGER.lock().unwrap();
        *global_manager = Some(manager.clone());
    }

    // åˆ›å»ºè¿›åº¦å›è°ƒå‡½æ•°ï¼Œç”¨äºå‘é€è¿›åº¦äº‹ä»¶åˆ°å‰ç«¯
    let app_handle_clone = app_handle.clone();
    let progress_callback = move |progress: crate::core::layered_commit_manager::LayeredCommitProgress| {
        let progress_json = serde_json::json!({
            "session_id": progress.session_id,
            "current_step": progress.current_step,
            "total_steps": progress.total_steps,
            "status": progress.status,
            "current_file": progress.current_file,
            "file_summaries": progress.file_summaries
        });

        let _ = app_handle_clone.emit("layered-commit-progress", &progress_json);
    };

    // è°ƒç”¨çœŸæ­£çš„åˆ†å±‚æäº¤é€»è¾‘
    let result = manager.execute_layered_commit(
        &templateId,
        stagedFiles,
        branchName,
        repository_path,
        progress_callback,
    ).await;

    // æ¸…ç†å…¨å±€ç®¡ç†å™¨å®ä¾‹ - Author: Evilek, Date: 2025-01-09
    {
        let mut global_manager = LAYERED_COMMIT_MANAGER.lock().unwrap();
        *global_manager = None;
    }

    match result {
        Ok(result) => {
            Ok(result)
        },
        Err(e) => {
            Err(format!("åˆ†å±‚æäº¤æ‰§è¡Œå¤±è´¥: {}", e))
        }
    }
}





/// å–æ¶ˆåˆ†å±‚æäº¤
/// Author: Evilek, Date: 2025-01-09
#[tauri::command]
pub async fn cancel_layered_commit() -> Result<(), String> {
    let global_manager = LAYERED_COMMIT_MANAGER.lock().unwrap();
    if let Some(manager) = global_manager.as_ref() {
        manager.cancel();
        Ok(())
    } else {
        Err("æ²¡æœ‰æ­£åœ¨æ‰§è¡Œçš„åˆ†å±‚æäº¤ä»»åŠ¡".to_string())
    }
}

/// æ£€æŸ¥æ˜¯å¦éœ€è¦é¦–æ¬¡å¯åŠ¨å¼•å¯¼
/// Author: Evilek, Date: 2025-01-09
#[tauri::command]
pub async fn check_first_time_setup(
    ai_manager: State<'_, Mutex<AIManager>>,
) -> Result<bool, String> {
    let manager = ai_manager.lock().await;
    let config = manager.get_config().await;

    // æ£€æŸ¥å½“å‰é€‰æ‹©çš„æä¾›å•†æ˜¯å¦é…ç½®äº†APIå¯†é’¥
    let needs_setup = match config.base.provider.as_str() {
        "OpenAI" => config.providers.openai.api_key.is_empty(),
        "Ollama" => false, // Ollamaé€šå¸¸ä¸éœ€è¦APIå¯†é’¥
        "Zhipu" => config.providers.zhipu.api_key.is_empty(),
        "Anthropic" => config.providers.anthropic.api_key.is_empty(),
        "DashScope" => config.providers.dashscope.api_key.is_empty(),
        "Doubao" => config.providers.doubao.api_key.is_empty(),
        "Gemini" => config.providers.gemini.api_key.is_empty(),
        "Deepseek" => config.providers.deepseek.api_key.is_empty(),
        "Siliconflow" => config.providers.siliconflow.api_key.is_empty(),
        "OpenRouter" => config.providers.openrouter.api_key.is_empty(),
        "Together" => config.providers.together.api_key.is_empty(),
        "Mistral" => config.providers.mistral.api_key.is_empty(),
        "BaiduQianfan" => config.providers.baidu_qianfan.api_key.is_empty() || config.providers.baidu_qianfan.secret_key.is_empty(),
        "AzureOpenAI" => config.providers.azure_openai.api_key.is_empty() || config.providers.azure_openai.endpoint.is_empty(),
        "Cloudflare" => config.providers.cloudflare.api_key.is_empty() || config.providers.cloudflare.account_id.is_empty(),
        "VertexAI" => config.providers.vertexai.project_id.is_empty() || config.providers.vertexai.credentials_path.is_empty(),
        "Groq" => config.providers.groq.api_key.is_empty(),
        _ => true, // æœªçŸ¥æä¾›å•†ï¼Œéœ€è¦è®¾ç½®
    };

    Ok(needs_setup)
}

/// æµ‹è¯•AIè¿æ¥
/// Author: Evilek, Date: 2025-01-09
#[tauri::command]
pub async fn test_ai_connection(
    ai_manager: State<'_, Mutex<AIManager>>,
) -> Result<String, String> {
    let manager = ai_manager.lock().await;
    let config = manager.get_config().await;

    // æ„å»ºç®€å•çš„æµ‹è¯•è¯·æ±‚
    let test_request = crate::core::ai_provider::AIRequest {
        messages: vec![
            crate::core::ai_provider::ChatMessage {
                role: "user".to_string(),
                content: "Hello, please respond with 'Connection test successful'".to_string(),
            }
        ],
        model: config.base.model.clone(), // ä¿®å¤ï¼šæ·»åŠ modelå­—æ®µ
        temperature: Some(0.1),
        max_tokens: Some(50),
        stream: Some(false),
    };

    // å°è¯•å‘é€è¯·æ±‚ï¼Œä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•å
    match manager.generate_commit_message(test_request).await {
        Ok(response) => {
            if response.content.contains("successful") || response.content.contains("æˆåŠŸ") {
                Ok("AIè¿æ¥æµ‹è¯•æˆåŠŸ".to_string())
            } else {
                Ok(format!("AIå“åº”æ­£å¸¸ï¼Œè¿”å›å†…å®¹: {}", response.content))
            }
        },
        Err(e) => {
            Err(format!("AIè¿æ¥æµ‹è¯•å¤±è´¥: {}", e))
        }
    }
}

/// è·å–åˆ†å±‚æäº¤ä¼šè¯åˆ—è¡¨
/// ä½œè€…ï¼šEvilek
/// ç¼–å†™æ—¥æœŸï¼š2025-08-04
#[tauri::command]
pub async fn get_layered_sessions(
    ai_manager: State<'_, Mutex<AIManager>>,
) -> Result<Vec<String>, String> {
    let manager = ai_manager.lock().await;
    manager.get_layered_sessions().await
        .map_err(|e| format!("Failed to get layered sessions: {}", e))
}

/// æ ¹æ®ä¼šè¯IDè·å–å¯¹è¯è®°å½•
/// ä½œè€…ï¼šEvilek
/// ç¼–å†™æ—¥æœŸï¼š2025-08-04
#[tauri::command]
pub async fn get_conversation_records_by_session(
    ai_manager: State<'_, Mutex<AIManager>>,
    session_id: String,
) -> Result<Vec<ConversationRecord>, String> {
    let manager = ai_manager.lock().await;
    manager.get_conversation_records_by_session(&session_id).await
        .map_err(|e| format!("Failed to get conversation records by session: {}", e))
}

/// é‡æ–°åŠ è½½é»˜è®¤æ¨¡æ¿ï¼ˆæ¸…ç†ç¼“å­˜ï¼‰
/// ä½œè€…ï¼šEvilek
/// ç¼–å†™æ—¥æœŸï¼š2025-01-29
#[allow(dead_code)] // é¢„ç•™çš„ç®¡ç†åŠŸèƒ½ï¼Œæš‚æœªåœ¨å‰ç«¯ä½¿ç”¨
#[tauri::command]
pub async fn reload_default_templates(
    ai_manager: State<'_, Mutex<AIManager>>,
) -> Result<(), String> {
    let manager = ai_manager.lock().await;
    manager.reload_default_templates().await
        .map_err(|e| format!("Failed to reload templates: {}", e))
}

/// æ¸…ç†æ‰€æœ‰ç¼“å­˜å’Œé…ç½®æ–‡ä»¶
/// ä½œè€…ï¼šEvilek
/// ç¼–å†™æ—¥æœŸï¼š2025-01-29
#[allow(dead_code)] // é¢„ç•™çš„ç®¡ç†åŠŸèƒ½ï¼Œæš‚æœªåœ¨å‰ç«¯ä½¿ç”¨
#[tauri::command]
pub async fn clear_all_cache(
    ai_manager: State<'_, Mutex<AIManager>>,
) -> Result<(), String> {
    let manager = ai_manager.lock().await;
    manager.clear_all_cache().await
        .map_err(|e| format!("Failed to clear cache: {}", e))
}

/// æ£€æŸ¥å¹¶å¤„ç†æ–‡ä»¶tokené™åˆ¶
/// Author: Evilek
/// Date: 2025-01-08
/// å¯¹å•æ–‡ä»¶å˜æ›´å’Œæ–°å¢æ–‡ä»¶è¿›è¡Œtokenæ£€æŸ¥ï¼Œè¶…é™åˆ™åˆ†å‰²å¤„ç†
#[derive(serde::Serialize)]
pub struct FileTokenCheckResult {
    #[serde(rename = "processedFiles")]
    pub processed_files: Vec<String>,
    #[serde(rename = "needsSplit")]
    pub needs_split: bool,
}

#[tauri::command]
pub async fn check_and_process_file_tokens(
    ai_manager: State<'_, Mutex<AIManager>>,
    git_engine: State<'_, Mutex<crate::core::git_engine::GitEngine>>,
    filePaths: Vec<String>,
    template_id: Option<String>,
) -> Result<FileTokenCheckResult, String> {
    use crate::utils::token_counter::TokenCounter;
    use std::sync::Arc;
    use tokio::sync::RwLock;

    println!("ğŸ” [check_and_process_file_tokens] å¼€å§‹å¤„ç† {} ä¸ªæ–‡ä»¶", filePaths.len());

    let ai_manager_arc = Arc::new(RwLock::new(ai_manager.lock().await.clone()));
    let git_engine_arc = Arc::new(RwLock::new(git_engine.lock().await.clone()));

    println!("ğŸ” [check_and_process_file_tokens] è·å–AIé…ç½®...");
    // è·å–AIé…ç½®ä»¥ç¡®å®štokené™åˆ¶
    let ai_manager_guard = ai_manager_arc.read().await;
    let config = ai_manager_guard.get_config().await;
    let model_max_tokens = match config.base.model.as_str() {
        m if m.contains("gpt-4") => Some(8192),
        m if m.contains("gpt-3.5") => Some(4096),
        m if m.contains("claude") => Some(100000),
        m if m.contains("gemini") => Some(32768),
        m if m.contains("qwen2.5:32b") => Some(32768), // qwen2.5:32b æ”¯æŒ32kä¸Šä¸‹æ–‡
        m if m.contains("qwen") => Some(8192), // å…¶ä»–qwenæ¨¡å‹é»˜è®¤8k
        _ => Some(4096), // é»˜è®¤é™åˆ¶
    };
    drop(ai_manager_guard);
    println!("ğŸ” [check_and_process_file_tokens] æ¨¡å‹tokené™åˆ¶: {:?}", model_max_tokens);

    let mut processed_files = Vec::new();
    let mut needs_split = false;

    println!("ğŸ” [check_and_process_file_tokens] å¼€å§‹è·å–æ–‡ä»¶diff...");

    // æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨æ‰¹é‡diffè·å–ï¼Œé¿å…å•ä¸ªæ–‡ä»¶çš„é‡å¤Gitæ“ä½œ
    let git_engine_guard = git_engine_arc.read().await;
    let batch_diff_result = git_engine_guard.get_diff_summary(&filePaths);
    drop(git_engine_guard);

    // å¦‚æœæ‰¹é‡è·å–å¤±è´¥ï¼Œå›é€€åˆ°å•ä¸ªæ–‡ä»¶å¤„ç†ï¼ˆä½†æ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼‰
    let mut file_diffs = Vec::new();

    match batch_diff_result {
        Ok(batch_diff) => {
            println!("ğŸ” [check_and_process_file_tokens] ä½¿ç”¨æ‰¹é‡diffï¼Œé•¿åº¦: {}", batch_diff.len());
            // ç®€åŒ–å¤„ç†ï¼šå¦‚æœèƒ½è·å–åˆ°æ‰¹é‡diffï¼Œå°±å‡è®¾æ‰€æœ‰æ–‡ä»¶éƒ½æœ‰å˜æ›´
            // è¿™æ˜¯ä¸€ä¸ªæƒè¡¡ï¼šç‰ºç‰²ä¸€äº›ç²¾ç¡®æ€§æ¢å–æ€§èƒ½
            for file_path in &filePaths {
                // ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ†é…ä¸€éƒ¨åˆ†diffå†…å®¹ï¼ˆç®€åŒ–ä¼°ç®—ï¼‰
                let estimated_diff = format!("diff --git a/{} b/{}\n--- a/{}\n+++ b/{}\n@@ -1,10 +1,10 @@\n æ–‡ä»¶å˜æ›´å†…å®¹...",
                                            file_path, file_path, file_path, file_path);
                file_diffs.push((file_path.clone(), Some(estimated_diff)));
            }
        },
        Err(_) => {
            println!("âš ï¸ [check_and_process_file_tokens] æ‰¹é‡diffè·å–å¤±è´¥ï¼Œå›é€€åˆ°å•ä¸ªæ–‡ä»¶å¤„ç†");
            // å›é€€åˆ°åŸæ¥çš„é€»è¾‘ï¼Œä½†æ·»åŠ è¶…æ—¶ä¿æŠ¤
            let git_engine_guard = git_engine_arc.read().await;

            for (index, file_path) in filePaths.iter().enumerate() {
                println!("ğŸ” [check_and_process_file_tokens] å¤„ç†æ–‡ä»¶ {}/{}: {}", index + 1, filePaths.len(), file_path);

                // ä½¿ç”¨ä¼˜åŒ–åçš„Git diffè·å–
                let start_time = std::time::Instant::now();
                match git_engine_guard.get_simple_file_diff(file_path) {
                    Ok(diff_content) => {
                        let elapsed = start_time.elapsed();
                        println!("ğŸ” [check_and_process_file_tokens] æ–‡ä»¶ {} diffé•¿åº¦: {}, è€—æ—¶: {:?}", file_path, diff_content.len(), elapsed);
                        file_diffs.push((file_path.clone(), Some(diff_content)));
                    },
                    Err(e) => {
                        println!("âš ï¸ [check_and_process_file_tokens] æ–‡ä»¶ {} diffè·å–å¤±è´¥: {}", file_path, e);
                        file_diffs.push((file_path.clone(), None));
                    }
                }
            }
            drop(git_engine_guard);
        }
    }

    println!("ğŸ” [check_and_process_file_tokens] å®Œæˆdiffè·å–ï¼Œå¼€å§‹tokenåˆ†æ...");

    // æ™ºèƒ½åˆ†ç»„ç­–ç•¥ï¼šæ ¹æ®tokenä½¿ç”¨é‡å†³å®šå¤„ç†æ–¹å¼
    let mut total_tokens = 0u32;
    let mut large_files = Vec::new();
    let mut normal_files = Vec::new();

    // è®¡ç®—æ¯ä¸ªæ–‡ä»¶çš„tokenä½¿ç”¨é‡
    for (file_path, diff_content_opt) in file_diffs {
        if let Some(diff_content) = diff_content_opt {
            println!("ğŸ” [check_and_process_file_tokens] è®¡ç®—æ–‡ä»¶ {} çš„token...", file_path);
            let file_tokens = TokenCounter::estimate_file_diff_tokens(&file_path, &diff_content);
            println!("ğŸ” [check_and_process_file_tokens] æ–‡ä»¶ {} tokenæ•°: {}", file_path, file_tokens);

            // å•ä¸ªæ–‡ä»¶è¶…è¿‡é™åˆ¶ï¼Œéœ€è¦åˆ†å‰²
            if TokenCounter::is_over_limit(file_tokens, model_max_tokens) {
                println!("âš ï¸ [check_and_process_file_tokens] æ–‡ä»¶ {} è¶…è¿‡tokené™åˆ¶ï¼Œæ ‡è®°ä¸ºå¤§æ–‡ä»¶", file_path);
                needs_split = true;
                large_files.push((file_path, diff_content, file_tokens));
            } else {
                total_tokens += file_tokens;
                normal_files.push((file_path, diff_content, file_tokens));
            }
        } else {
            // diffè·å–å¤±è´¥çš„æ–‡ä»¶ç›´æ¥æ·»åŠ 
            println!("âš ï¸ [check_and_process_file_tokens] æ–‡ä»¶ {} diffè·å–å¤±è´¥ï¼Œç›´æ¥æ·»åŠ ", file_path);
            processed_files.push(file_path);
        }
    }

    println!("ğŸ” [check_and_process_file_tokens] Tokenåˆ†æå®Œæˆ - å¤§æ–‡ä»¶: {}, æ™®é€šæ–‡ä»¶: {}, æ€»token: {}",
             large_files.len(), normal_files.len(), total_tokens);

    // å¤„ç†å¤§æ–‡ä»¶ï¼šéœ€è¦åˆ†å‰²
    for (file_path, diff_content, _) in large_files {
        // æ£€æŸ¥æ˜¯å¦ä¸ºæ–°å¢æ–‡ä»¶
        if diff_content.contains("new file mode") || diff_content.starts_with("+++") {
            // æ–°å¢æ–‡ä»¶ï¼šæˆªå–å‰é¢éƒ¨åˆ†
            processed_files.push(format!("{}#truncated", file_path));
        } else {
            // å˜æ›´æ–‡ä»¶ï¼šæ ‡è®°éœ€è¦åˆ†å‰²
            processed_files.push(format!("{}#split", file_path));
        }
    }

    // å¤„ç†æ™®é€šæ–‡ä»¶ï¼šæ¯ä¸ªæ–‡ä»¶å•ç‹¬å¤„ç†ï¼Œè¶…è¿‡tokené™åˆ¶æ—¶è‡ªåŠ¨åˆ†å‰²
    // Author: Evilek, Date: 2025-01-09 - ç§»é™¤æ‰¹é‡åˆå¹¶é€»è¾‘ï¼Œæ”¹ä¸ºå•æ–‡ä»¶ç‹¬ç«‹å¤„ç†
    for (file_path, _, file_tokens) in normal_files {
        // è·å–æ¨¡æ¿çš„max_tokensé…ç½®ä½œä¸ºåˆ†å‰²ä¾æ®
        // Author: Evilek, Date: 2025-01-09 - ä¿®å¤PromptManagerå®ä¾‹åŒ–é—®é¢˜ï¼Œä½¿ç”¨AIç®¡ç†å™¨ä¸­çš„å®ä¾‹
        let template_max_tokens = if let Some(ref template_id_str) = template_id {
            let ai_manager_guard = ai_manager_arc.read().await;
            let prompt_manager = ai_manager_guard.get_prompt_manager().await;
            prompt_manager.get_template_config(template_id_str)
                .and_then(|(max_tokens, _)| max_tokens)
                .unwrap_or(1000) // ä¿®å¤ï¼šå¢åŠ é»˜è®¤å€¼åˆ°1000 tokensï¼Œé¿å…è¿‡åº¦åˆ†å‰²
        } else {
            1000 // ä¿®å¤ï¼šå¢åŠ é»˜è®¤å€¼
        };

        // ä½¿ç”¨æ¨¡æ¿çš„max_tokensä½œä¸ºåˆ†å‰²çš„å®‰å…¨é™åˆ¶ï¼ˆä¿ç•™30%ä½™é‡ç»™æ–‡ä»¶åå’Œæ ¼å¼ï¼‰
        let safe_limit = (template_max_tokens as f32 * 0.7) as u32;

        if file_tokens > safe_limit {
            // æ–‡ä»¶è¶…è¿‡é™åˆ¶ï¼Œæ ‡è®°ä¸ºéœ€è¦åˆ†å‰²
            processed_files.push(format!("{}#split", file_path));
            needs_split = true;
        } else {
            // æ–‡ä»¶å¤§å°åˆé€‚ï¼Œç›´æ¥å¤„ç†
            processed_files.push(file_path);
        }
    }

    println!("ğŸ” [check_and_process_file_tokens] å¤„ç†å®Œæˆ - è¾“å‡ºæ–‡ä»¶: {:?}, éœ€è¦åˆ†å‰²: {}",
             processed_files, needs_split);

    Ok(FileTokenCheckResult {
        processed_files,
        needs_split,
    })
}
