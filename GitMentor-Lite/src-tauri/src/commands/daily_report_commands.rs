use crate::core::git_engine::GitEngine;
use crate::core::report_engine::{AnalysisEngine, CacheManager};
use crate::types::git_types::{
    AnalysisConfig, CommitAnalysis, CommitDetailAnalysis, Contributor, ImpactLevel, Report,
    ReportMeta, Repository,
};
use chrono::Utc;
use std::collections::HashMap;
use tauri::{Manager, State};
use tokio::sync::Mutex;
use uuid::Uuid;

// æ—¥æŠ¥ç”Ÿæˆç›¸å…³å‘½ä»¤ - Author: Evilek, Date: 2025-08-21

/// è·å–å¯ç”¨ä»“åº“åˆ—è¡¨
#[tauri::command]
pub async fn get_available_repositories(
    repoPaths: Vec<String>,
    git_engine: State<'_, Mutex<GitEngine>>,
) -> Result<Vec<Repository>, String> {
    let engine = git_engine.lock().await;
    engine
        .get_available_repositories(repoPaths)
        .map_err(|e| format!("Failed to get repositories: {}", e))
}

/// è·å–ä»“åº“è´¡çŒ®è€…åˆ—è¡¨
#[tauri::command]
pub async fn get_repo_contributors(
    repoPaths: Vec<String>,
    git_engine: State<'_, Mutex<GitEngine>>,
) -> Result<Vec<Contributor>, String> {
    let engine = git_engine.lock().await;
    engine
        .get_repo_contributors(repoPaths)
        .map_err(|e| format!("Failed to get contributors: {}", e))
}

/// åˆ†ææäº¤è®°å½•
#[tauri::command]
pub async fn analyze_commits(
    config: AnalysisConfig,
    git_engine: State<'_, Mutex<GitEngine>>,
) -> Result<CommitAnalysis, String> {
    let engine = git_engine.lock().await;
    engine
        .analyze_commits(config)
        .map_err(|e| format!("Failed to analyze commits: {}", e))
}

/// åˆ†æå•ä¸ªæäº¤å¹¶ç¼“å­˜ç»“æœ
#[tauri::command]
pub async fn analyze_and_cache_commit(
    repo_path: String,
    commit_id: String,
    app_handle: tauri::AppHandle,
) -> Result<CommitDetailAnalysis, String> {
    // è·å–åº”ç”¨æ•°æ®ç›®å½•
    let app_dir = app_handle
        .path()
        .app_data_dir()
        .map_err(|e| format!("Failed to get app data dir: {}", e))?;

    // åˆ›å»ºåˆ†æå¼•æ“
    let analysis_engine = AnalysisEngine::new(&app_dir)
        .map_err(|e| format!("Failed to create analysis engine: {}", e))?;

    // è·å– Git å¼•æ“
    let git_engine_state = app_handle.state::<Mutex<GitEngine>>();
    let git_engine = git_engine_state.lock().await;

    // è·å–æäº¤ä¿¡æ¯
    let commit_info = git_engine
        .get_commit_info(&repo_path, &commit_id)
        .map_err(|e| format!("Failed to get commit info: {}", e))?;

    // è·å–æ–‡ä»¶å·®å¼‚ä¿¡æ¯
    let diff_info = git_engine
        .get_commit_diff(&repo_path, &commit_id)
        .map_err(|e| format!("Failed to get diff info: {}", e))?;

    // åˆ†ææäº¤
    let analysis = analysis_engine
        .analyze_commit(&repo_path, &commit_id, &commit_info, Some(&diff_info))
        .await
        .map_err(|e| format!("Failed to analyze commit: {}", e))?;

    Ok(analysis)
}

/// ç”Ÿæˆå¢å¼ºç‰ˆæ—¥æŠ¥
#[tauri::command]
pub async fn generate_enhanced_daily_report(
    config: AnalysisConfig,
    app_handle: tauri::AppHandle,
) -> Result<Report, String> {
    println!("å¼€å§‹ç”Ÿæˆå¢å¼ºç‰ˆæ—¥æŠ¥...");
    println!(
        "é…ç½®ä¿¡æ¯: ä»“åº“æ•°é‡={}, ç”¨æˆ·æ•°é‡={}, å¼€å§‹æ—¥æœŸ={}, ç»“æŸæ—¥æœŸ={}",
        config.repoPaths.len(),
        config.userEmails.len(),
        config.startDate,
        config.endDate
    );

    let report_id = Uuid::new_v4().to_string();
    let created_at = Utc::now().to_rfc3339();

    // è·å–åº”ç”¨æ•°æ®ç›®å½•
    let app_dir = app_handle
        .path()
        .app_data_dir()
        .map_err(|e| format!("Failed to get app data dir: {}", e))?;
    println!("åº”ç”¨æ•°æ®ç›®å½•: {:?}", app_dir);

    // åˆ›å»ºåˆ†æå¼•æ“
    let analysis_engine = AnalysisEngine::new(&app_dir)
        .map_err(|e| format!("Failed to create analysis engine: {}", e))?;
    println!("åˆ†æå¼•æ“åˆ›å»ºæˆåŠŸ");

    // è·å– Git å¼•æ“
    let git_engine_state = app_handle.state::<Mutex<GitEngine>>();
    let git_engine = git_engine_state.lock().await;
    println!("Git å¼•æ“è·å–æˆåŠŸ");

    // åˆ†ææ‰€æœ‰æäº¤
    let mut all_analyses = Vec::new();
    let mut total_commits_found = 0;

    println!("å¼€å§‹åˆ†æ {} ä¸ªä»“åº“", config.repoPaths.len());

    for repo_path in &config.repoPaths {
        println!("æ­£åœ¨å¤„ç†ä»“åº“: {}", repo_path);

        // è·å–ä»“åº“åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„æäº¤
        let commits = git_engine
            .get_commits_in_date_range(repo_path, &config.startDate, &config.endDate)
            .map_err(|e| format!("Failed to get commits: {}", e))?;

        total_commits_found += commits.len();
        println!(
            "ä»“åº“ {} åœ¨ {} è‡³ {} æœŸé—´æ‰¾åˆ° {} ä¸ªæäº¤",
            repo_path,
            config.startDate,
            config.endDate,
            commits.len()
        );

        // è¿‡æ»¤æŒ‡å®šç”¨æˆ·çš„æäº¤
        let filtered_commits: Vec<_> = if config.userEmails.is_empty() {
            println!("æœªæŒ‡å®šç”¨æˆ·ï¼ŒåŒ…å«æ‰€æœ‰æäº¤");
            commits
        } else {
            let user_list = config.userEmails.join(", ");
            println!("æŒ‡å®šç”¨æˆ·: {}", user_list);
            commits
                .into_iter()
                .filter(|c| {
                    let include = config.userEmails.contains(&c.email);
                    if !include {
                        println!("è·³è¿‡æäº¤ {} (ç”¨æˆ·: {} ä¸åœ¨æŒ‡å®šç”¨æˆ·åˆ—è¡¨)", c.hash, c.email);
                    }
                    include
                })
                .collect()
        };

        println!(
            "ä»“åº“ {} è¿‡æ»¤åæœ‰ {} ä¸ªæäº¤",
            repo_path,
            filtered_commits.len()
        );

        // åˆ†ææ¯ä¸ªæäº¤
        for commit in filtered_commits {
            println!(
                "æ­£åœ¨åˆ†ææäº¤: {} - {}",
                commit.hash,
                commit.message.lines().next().unwrap_or("")
            );
            match analysis_engine
                .analyze_commit(repo_path, &commit.hash, &commit, None)
                .await
            {
                Ok(analysis) => {
                    all_analyses.push(analysis);
                    println!("æäº¤ {} åˆ†ææˆåŠŸ", commit.hash);
                }
                Err(e) => {
                    eprintln!("Failed to analyze commit {}: {}", commit.hash, e);
                    println!("æäº¤ {} åˆ†æå¤±è´¥: {}", commit.hash, e);
                }
            }
        }
    }

    println!(
        "æ€»å…±æ‰¾åˆ° {} ä¸ªæäº¤ï¼ŒæˆåŠŸåˆ†æ {} ä¸ª",
        total_commits_found,
        all_analyses.len()
    );

    if all_analyses.is_empty() {
        println!("è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æäº¤åˆ†æç»“æœ");
    }

    // ç”ŸæˆæŠ¥å‘Š
    println!("æ­£åœ¨ç”ŸæˆæŠ¥å‘Šå†…å®¹...");
    let title = format!("å¼€å‘æ—¥æŠ¥ - {} è‡³ {}", config.startDate, config.endDate);
    let content = generate_enhanced_report_content(&all_analyses, &config)?;

    println!("æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œå†…å®¹é•¿åº¦: {} å­—ç¬¦", content.len());

    Ok(Report {
        id: report_id,
        title,
        content,
        format: "markdown".to_string(),
        created_at,
        config,
    })
}

/// ç”Ÿæˆå¢å¼ºç‰ˆæŠ¥å‘Šå†…å®¹
fn generate_enhanced_report_content(
    analyses: &[CommitDetailAnalysis],
    config: &AnalysisConfig,
) -> Result<String, String> {
    let mut content = String::new();

    // æŠ¥å‘Šæ ‡é¢˜
    content.push_str(&format!("# å¼€å‘æ—¥æŠ¥\n\n"));
    content.push_str(&format!(
        "**æŠ¥å‘Šå‘¨æœŸ**: {} è‡³ {}\n\n",
        config.startDate, config.endDate
    ));
    content.push_str(&format!(
        "**ç”Ÿæˆæ—¶é—´**: {}\n\n",
        Utc::now().format("%Y-%m-%d %H:%M:%S UTC")
    ));
    content.push_str(&format!("**æ€»æäº¤æ•°**: {}\n\n", analyses.len()));

    if analyses.is_empty() {
        content.push_str("*åœ¨é€‰å®šçš„æ—¶é—´èŒƒå›´å†…æ²¡æœ‰æ‰¾åˆ°æäº¤è®°å½•ã€‚*\n");
        return Ok(content);
    }

    // ç»Ÿè®¡æ¦‚è§ˆ
    let total_insertions: u32 = analyses.iter().map(|a| a.insertions).sum();
    let total_deletions: u32 = analyses.iter().map(|a| a.deletions).sum();
    let unique_files: std::collections::HashSet<_> = analyses
        .iter()
        .flat_map(|a| a.files_changed.iter().map(|f| &f.file_path))
        .collect();

    content.push_str("## ğŸ“Š ç»Ÿè®¡æ¦‚è§ˆ\n\n");
    content.push_str(&format!("- **æ´»è·ƒä»“åº“æ•°**: {}\n", config.repoPaths.len()));
    content.push_str(&format!("- **æ–‡ä»¶å˜æ›´**: {} ä¸ªæ–‡ä»¶\n", unique_files.len()));
    content.push_str(&format!(
        "- **ä»£ç å˜æ›´**: +{} / -{}\n\n",
        total_insertions, total_deletions
    ));

    // é‡è¦æäº¤
    let important_commits: Vec<_> = analyses
        .iter()
        .filter(|a| a.impact_level == ImpactLevel::Critical || a.impact_level == ImpactLevel::High)
        .collect();

    if !important_commits.is_empty() {
        content.push_str("## ğŸ¯ é‡è¦æäº¤\n\n");
        for analysis in important_commits.iter().take(5) {
            let repo_name = std::path::Path::new(&analysis.repo_path)
                .file_name()
                .and_then(|s| s.to_str())
                .unwrap_or("Unknown");

            content.push_str(&format!(
                "### [{}] {} - {}\n",
                match analysis.impact_level {
                    ImpactLevel::Critical => "Critical",
                    ImpactLevel::High => "High",
                    ImpactLevel::Medium => "Medium",
                    ImpactLevel::Low => "Low",
                },
                repo_name,
                &analysis.commit_id[..7]
            ));
            content.push_str(&format!(
                "**ä½œè€…**: {} ({})\n",
                analysis.author, analysis.email
            ));
            content.push_str(&format!(
                "**æ—¶é—´**: {}\n",
                chrono::DateTime::from_timestamp(analysis.timestamp, 0)
                    .map(|dt| dt.format("%Y-%m-%d %H:%M:%S").to_string())
                    .unwrap_or_else(|| "Unknown".to_string())
            ));
            content.push_str(&format!("**æ‘˜è¦**: {}\n\n", analysis.summary));

            // æ˜¾ç¤ºä¸»è¦å˜æ›´æ–‡ä»¶
            if !analysis.files_changed.is_empty() {
                content.push_str("**ä¸»è¦å˜æ›´æ–‡ä»¶**:\n");
                for file in analysis.files_changed.iter().take(3) {
                    content.push_str(&format!(
                        "- {} ({})\n",
                        file.file_path,
                        match file.change_type {
                            crate::types::git_types::FileChangeType::Added => "æ–°å¢",
                            crate::types::git_types::FileChangeType::Modified => "ä¿®æ”¹",
                            crate::types::git_types::FileChangeType::Deleted => "åˆ é™¤",
                            crate::types::git_types::FileChangeType::Renamed => "é‡å‘½å",
                            crate::types::git_types::FileChangeType::Copied => "å¤åˆ¶",
                        }
                    ));
                }
                content.push_str("\n");
            }
        }
    }

    // æŒ‰ä»“åº“ç»Ÿè®¡
    content.push_str("## ğŸ“ å„ä»“åº“æäº¤æƒ…å†µ\n\n");
    let mut repo_stats: HashMap<String, Vec<&CommitDetailAnalysis>> = HashMap::new();

    for analysis in analyses {
        let repo_name = std::path::Path::new(&analysis.repo_path)
            .file_name()
            .and_then(|s| s.to_str())
            .unwrap_or("Unknown")
            .to_string();

        repo_stats.entry(repo_name).or_default().push(analysis);
    }

    for (repo_name, repo_analyses) in repo_stats {
        content.push_str(&format!("### {}\n", repo_name));
        content.push_str(&format!("- **æäº¤æ•°**: {}\n", repo_analyses.len()));

        // ç»Ÿè®¡è´¡çŒ®è€…
        let mut contributors: HashMap<String, u32> = HashMap::new();
        for analysis in &repo_analyses {
            *contributors.entry(analysis.author.clone()).or_insert(0) += 1;
        }

        content.push_str("- **è´¡çŒ®è€…**: ");
        for (name, count) in contributors {
            content.push_str(&format!("{}({}) ", name, count));
        }
        content.push_str("\n\n");
    }

    // æŒ‰è´¡çŒ®è€…ç»Ÿè®¡
    content.push_str("## ğŸ‘¥ è´¡çŒ®è€…è¯¦æƒ…\n\n");
    let mut contributor_stats: HashMap<String, Vec<&CommitDetailAnalysis>> = HashMap::new();

    for analysis in analyses {
        contributor_stats
            .entry(analysis.email.clone())
            .or_default()
            .push(analysis);
    }

    for (email, user_analyses) in contributor_stats {
        if let Some(first) = user_analyses.first() {
            content.push_str(&format!("### {} ({})\n", first.author, email));
            content.push_str(&format!("- **æäº¤æ•°**: {}\n", user_analyses.len()));

            // ç»Ÿè®¡å½±å“çº§åˆ«
            let mut impact_counts = HashMap::new();
            for analysis in &user_analyses {
                *impact_counts
                    .entry(format!("{:?}", analysis.impact_level))
                    .or_insert(0) += 1;
            }

            content.push_str("- **å½±å“çº§åˆ«åˆ†å¸ƒ**: ");
            for (level, count) in impact_counts {
                content.push_str(&format!("{}({}) ", level, count));
            }
            content.push_str("\n\n");
        }
    }

    // æ ‡ç­¾ç»Ÿè®¡
    content.push_str("## ğŸ·ï¸ æ ‡ç­¾ç»Ÿè®¡\n\n");
    let mut tag_counts: HashMap<String, u32> = HashMap::new();
    for analysis in analyses {
        for tag in &analysis.tags {
            *tag_counts.entry(tag.clone()).or_insert(0) += 1;
        }
    }

    let mut sorted_tags: Vec<_> = tag_counts.into_iter().collect();
    sorted_tags.sort_by(|a, b| b.1.cmp(&a.1));

    for (tag, count) in sorted_tags.iter().take(10) {
        content.push_str(&format!("- **{}**: {} æ¬¡\n", tag, count));
    }

    content.push_str("\n---\n*æŠ¥å‘Šç”± GitMentor è‡ªåŠ¨ç”Ÿæˆ*\n");

    Ok(content)
}

/// è·å–æäº¤ç¼“å­˜çŠ¶æ€
#[tauri::command]
pub async fn get_commit_cache_status(
    repo_path: String,
    commit_ids: Vec<String>,
    app_handle: tauri::AppHandle,
) -> Result<HashMap<String, bool>, String> {
    let app_dir = app_handle
        .path()
        .app_data_dir()
        .map_err(|e| format!("Failed to get app data dir: {}", e))?;

    let cache_manager = CacheManager::new(&app_dir);
    let mut status = HashMap::new();

    for commit_id in commit_ids {
        status.insert(
            commit_id.clone(),
            cache_manager.cache_exists(&repo_path, &commit_id),
        );
    }

    Ok(status)
}

/// æ¸…ç†è¿‡æœŸç¼“å­˜
#[tauri::command]
pub async fn cleanup_cache(days_old: u64, app_handle: tauri::AppHandle) -> Result<bool, String> {
    let app_dir = app_handle
        .path()
        .app_data_dir()
        .map_err(|e| format!("Failed to get app data dir: {}", e))?;

    let cache_manager = CacheManager::new(&app_dir);
    cache_manager
        .cleanup_old_cache(days_old)
        .map_err(|e| format!("Failed to cleanup cache: {}", e))?;

    Ok(true)
}

/// ç”Ÿæˆæ—¥æŠ¥ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
#[tauri::command]
pub async fn generate_daily_report(
    analysis: CommitAnalysis,
    template: Option<String>,
) -> Result<Report, String> {
    let report_id = Uuid::new_v4().to_string();
    let created_at = Utc::now().to_rfc3339();

    // ç”ŸæˆæŠ¥å‘Šæ ‡é¢˜
    let title = format!("Daily Report - {}", analysis.analysis_period);

    // ä½¿ç”¨é»˜è®¤æ¨¡æ¿ç”ŸæˆæŠ¥å‘Šå†…å®¹
    let content = generate_report_content(&analysis, template.as_deref())?;

    Ok(Report {
        id: report_id,
        title,
        content,
        format: "markdown".to_string(),
        created_at,
        config: AnalysisConfig {
            repoPaths: analysis.commits_by_repo.keys().cloned().collect(),
            userEmails: analysis.commits_by_user.keys().cloned().collect(),
            startDate: "".to_string(), // TODO: ä»analysisä¸­æå–
            endDate: "".to_string(),   // TODO: ä»analysisä¸­æå–
        },
    })
}

/// ç”ŸæˆæŠ¥å‘Šå†…å®¹
fn generate_report_content(
    analysis: &CommitAnalysis,
    _template: Option<&str>,
) -> Result<String, String> {
    let mut content = String::new();

    // æŠ¥å‘Šæ ‡é¢˜
    content.push_str(&format!("# å¼€å‘æ—¥æŠ¥\n\n"));
    content.push_str(&format!("**åˆ†æå‘¨æœŸ**: {}\n\n", analysis.analysis_period));
    content.push_str(&format!("**æ€»æäº¤æ•°**: {}\n\n", analysis.total_commits));

    // æŒ‰ç”¨æˆ·ç»Ÿè®¡
    content.push_str("## ğŸ‘¥ ç”¨æˆ·æäº¤ç»Ÿè®¡\n\n");
    for (email, commits) in &analysis.commits_by_user {
        let user_name = commits
            .first()
            .map(|c| c.author.as_str())
            .unwrap_or("Unknown");
        content.push_str(&format!("### {} ({})\n", user_name, email));
        content.push_str(&format!("- æäº¤æ•°é‡: {}\n", commits.len()));
        content.push_str("- ä¸»è¦æäº¤:\n");

        for (i, commit) in commits.iter().take(5).enumerate() {
            content.push_str(&format!(
                "  {}. `{}` {}\n",
                i + 1,
                commit.short_hash,
                commit.message.lines().next().unwrap_or("")
            ));
        }
        content.push_str("\n");
    }

    // æŒ‰ä»“åº“ç»Ÿè®¡
    content.push_str("## ğŸ“ ä»“åº“æäº¤ç»Ÿè®¡\n\n");
    for (repo_name, commits) in &analysis.commits_by_repo {
        content.push_str(&format!("### {}\n", repo_name));
        content.push_str(&format!("- æäº¤æ•°é‡: {}\n", commits.len()));

        // ç»Ÿè®¡è¯¥ä»“åº“çš„ç”¨æˆ·è´¡çŒ®
        let mut user_commits: HashMap<String, usize> = HashMap::new();
        for commit in commits {
            *user_commits.entry(commit.author.clone()).or_insert(0) += 1;
        }

        content.push_str("- è´¡çŒ®è€…:\n");
        for (user, count) in user_commits {
            content.push_str(&format!("  - {}: {} æ¬¡æäº¤\n", user, count));
        }
        content.push_str("\n");
    }

    // æ–‡ä»¶å˜æ›´ç»Ÿè®¡
    if !analysis.file_changes.is_empty() {
        content.push_str("## ğŸ“ æ–‡ä»¶å˜æ›´ç»Ÿè®¡\n\n");
        let mut sorted_files: Vec<_> = analysis.file_changes.iter().collect();
        sorted_files.sort_by(|a, b| b.1.cmp(a.1));

        content.push_str("| æ–‡ä»¶ | å˜æ›´æ¬¡æ•° |\n");
        content.push_str("|------|----------|\n");

        for (file, count) in sorted_files.iter().take(10) {
            content.push_str(&format!("| {} | {} |\n", file, count));
        }
        content.push_str("\n");
    }

    // æŠ¥å‘Šç”Ÿæˆæ—¶é—´
    content.push_str(&format!(
        "---\n*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {}*\n",
        Utc::now().format("%Y-%m-%d %H:%M:%S UTC")
    ));

    Ok(content)
}

// TODO: å®ç°å†å²æŠ¥å‘Šç®¡ç†åŠŸèƒ½
/// ä¿å­˜æŠ¥å‘Š
#[tauri::command]
pub async fn save_report(report: Report) -> Result<String, String> {
    // TODO: å®ç°æŠ¥å‘Šä¿å­˜åˆ°æœ¬åœ°å­˜å‚¨
    Ok(report.id)
}

/// è·å–å†å²æŠ¥å‘Šåˆ—è¡¨
#[tauri::command]
pub async fn get_history_reports() -> Result<Vec<ReportMeta>, String> {
    // TODO: ä»æœ¬åœ°å­˜å‚¨åŠ è½½å†å²æŠ¥å‘Š
    Ok(vec![])
}

/// åˆ é™¤æŠ¥å‘Š
#[tauri::command]
pub async fn delete_report(_report_id: String) -> Result<bool, String> {
    // TODO: ä»æœ¬åœ°å­˜å‚¨åˆ é™¤æŠ¥å‘Š
    Ok(true)
}
